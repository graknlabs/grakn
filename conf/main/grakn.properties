#
# Grakn - A Distributed Semantic Database
# Copyright (C) 2016  Grakn Labs Limited
#
# Grakn is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Grakn is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Grakn. If not, see <http://www.gnu.org/licenses/gpl.txt>.
#

############################# Graph Configuration #############################

# The factory determines which graph backend Grakn should use. Out of the box,
# Grakn provides ai.grakn.factory.{JanusInternalFactory, JanusInternalFactory}.
#
# - JanusInternalFactory is a factory providing Janus graphs, that can be configured
#   to run on different database storage backends (see Janus configuration section).
#   Grakn recommends using JanusInternalFactory and cassandra for all production
#   applications.
# - TinkerInternalFactory is a factory providing TinkerGraphs, in-memory non-persisted
#   graphs. Does not support transactions and due to lack of indexing, cannot scale.
#   This factory should be used for testing or for toy examples, never in
#   production.
factory.internal=ai.grakn.factory.JanusInternalFactory

# Factory that provides graphs to the analytics component. Graphs provided by this
# factory are not used for querying or building graphs. By default, Grakn supports
# ai.grakn.factory.{JanusHadoopInternalFactory, TinkerInternalFactory}.
#
# - JanusHadoopInternalFactory provides a wrapper around a hadoop graph. Wraps around
#   a gremlin HadoopGraph (IS THIS TRUE)
# - TinkerInternalFactory is a factory providing TinkerGraphs, in-memory non-persisted
#   graphs. Does not support transactions and due to lack of indexing, cannot scale.
#   This factory should be used for testing or for toy examples, never in
#   production.
factory.analytics=ai.grakn.factory.JanusHadoopInternalFactory

# The name of the default graph keyspace.
graph.default-keyspace=grakn

# Number of instances after which Grakn should shard any type node. Sharding is the
# mechanism by which Grakn mitigates against supernodes.
# A larger sharding threshold will increase runtime as the graph grows and decrease
# the likelihood of supernodes. A threshold that is too small will create supernodes
# more frequently.
graph.sharding-threshold=10000

# How long, in milliseconds, graph-level ontology elements will be
# cached. Longer cache timeouts means writing will be much faster, particularly for
# batch loading. Shorter cache timeouts are better for memory usage and in some cases
# may help avoid GC issues.
graph.ontology-cache-timeout-ms=600000

############################# Server Configuration #############################

# Set the IP address that Grakn engine server will listen on.
server.host=0.0.0.0
# Port number to use for Grakn engine server to listen on. If provided port = 0
# then an arbitrary available port will be used
server.port=4567
# Set the external folder serving static files to the Grakn dashboard.
server.static-file-dir=../assets/

# May either be "true" or "false" to enable authentication for protected REST endpoints.
# When true must include the JWT token
password.protected=false
admin.password=grakn
# JWT json key used to encrypt and decrypt the token send in REST requests
# If authentication above (password.protected) is false, this property is not used
# JWT.secret=Anzdz9l4TG8N5y18oaTDueqJQca1aX7loaz0U8Hz

# The task manager is responsible for the maintaining the lifecycle of tasks, including
# restarting tasks when an engine instance dies. Out of the box, Grakn provides
# ai.grakn.engine.tasks.manager.{SingleQueueTaskManager, StandaloneTaskManager}.
#
# - StandaloneTaskManager is an in-memory implementation of the TaskManager.
#   Only for use in a testing environment; should the Grakn engine instance fail all
#   running or submitted tasks will be lost.
# - SingleQueueTaskManager is a distributed version of the TaskManager Kafka
#   and Zookeeper. For use in a cluster environment.
#
taskmanager.implementation=ai.grakn.engine.tasks.manager.RedisTaskManager

# Number of times to retry graph mutations if a temporary backend exception occurs
# during the mutation. If this number is set to 0, the server will not retry.
loader.repeat-commits=5

# The delay after which post processing tasks should begin to execute. This delay should
# be enough such that all initial duplicates have been created. A higher delay may
# slow down batch loading and a lower delay may result in duplicates in the graph.
tasks.postprocessing.delay=60000

# This defines the number of threads to be used when executing tasks. Consider
# increasing this number to increase engine task throughput and CPU usage.
# If the provided number of threads = 0 then the number of processors available to
# the Java virtual machine at startup time will be used.
loader.threads=0

############################# Logging Configuration #############################
# These properties are read directly by logback.xml

# Single directory under which to store log files. If using a relative path it will be relative
# to the JVM system variable "grakn.dir"
log.dirs=../logs/
# Specify the log verbosity level. This can be one of:
#
# ERROR: (critical errors indicating the application has failed)
# WARN:  (errors that will not affect the overall running of the application)
# INFO:  (minimally verbose, including Grakn engine lifecycle events)
# DEBUG: (verbose, non production use, server task lifecycle events)
# TRACE: (extraordinarily verbose, be brave, including graql query traversal paths,
#         extra task lifecycle events, kafka consumer offsets, etc)
log.level=INFO

############################# Janus Graph Configuration #############################
# See the Janus docs (http://docs.janusgraph.org/latest/config-ref.html)
# for more explanations of these properties.
# Any Janus property can be added to this file and will be forwarded to the
# Janus Graph library.

# The primary persistence provider used by Janus. Grakn recommends using Cassandra
# as it is the supported backend.
storage.backend=cassandra
# The hostname or comma-separated list of hostnames of storage backend servers
storage.hostname=127.0.0.1
# Cassandra thrift frame size in megabytes
storage.cassandra.frame-size-mb=200

#### Cassandra specific configuration ####

# Whether to enable Janusâ€™s database-level cache, which is shared across all transactions.
# Enabling this option speeds up traversals by holding hot graph elements in memory,
# but also increases the likelihood of reading stale data. Disabling it forces each transaction
# to independently fetch graph elements from storage before reading/writing them.
cache.db-cache=true
# How long in milliseconds database-level cache will keep entries after flushing them.
cache.db-cache-clean-wait=20
# Default expiration time in milliseconds for entries in the database-level cache.
# Set to 0 to disable expiration (cache entries live forever or until memory pressure
# triggers eviction).
cache.db-cache-time=180000
# Size of Janus's database cache in proportion to JVM size 0 (small) to 1 (large)
cache.db-cache-size=0.25

# Janus InputFormat configuration for using hadoop
# Not clear why these need to be set. See http://stackoverflow.com/questions/38524151/counting-vertices-on-a-titan-graph-using-sparkgraphcomputer-throws-org-apache-sp/38529076
# for more information.
# These two properties should be equal to the value of storage.backend and storage.hostname, respectively.
janusmr.ioformat.conf.storage.backend=cassandra
janusmr.ioformat.conf.storage.hostname=localhost
janusmr.ioformat.cf-name=edgestore

# Cassandra InputFormat configuration
# Not clear why these need to be set. See http://stackoverflow.com/questions/38524151/counting-vertices-on-a-titan-graph-using-sparkgraphcomputer-throws-org-apache-sp/38529076
# for more information.
cassandra.input.partitioner.class=org.apache.cassandra.dht.Murmur3Partitioner
cassandra.input.predicate=0c00020b0001000000000b000200000000020003000800047fffffff0000
cassandra.input.columnfamily=edgestore
cassandra.range.batch.size=4096
cassandra.thrift.framed.size_mb=1024

############################# Redis Configuration #############################
# IP or hostname on which Redis is listening for connections.
redis.host=localhost:6379
#redis.sentinel.host=localhost:26379

############################# Gremlin Configuration #############################

# Class that gremlin injects as a graph on which to run analytics
gremlin.graph=org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph
# Input API implementation on the graph. If the janus or graph backend is changed, this should change accordingly.
gremlin.hadoop.graphInputFormat=org.janusgraph.hadoop.formats.cassandra.CassandraInputFormat
# Output API implementation on the graph
gremlin.hadoop.graphOutputFormat=org.apache.tinkerpop.gremlin.hadoop.structure.io.gryo.GryoOutputFormat
# If the classpath has been provided on the remote machine
gremlin.hadoop.jarsInDistributedCache=true
# Where the results of operations are stored.
# gremlin.hadoop.outputLocation=/test/output
gremlin.hadoop.outputLocation=output

# TODO should be moved away from this file because it cannot be changed
gremlin.hadoop.inputLocation=none

############################# Spark Configuration #############################
#spark.master=spark://123.123.123.123:7077
spark.master=local[*]
#spark.executor.memory=1g
#spark.executor.cores=8
#spark.cores.max=24
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.ui.showConsoleProgress=false

############################# Hadoop Cluster configuration #############################
#fs.defaultFS=hdfs://123.123.123.123:9000
